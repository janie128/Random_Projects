{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Challenge\n",
    "## Predict service faults on Australia's largest telecommunications network\n",
    "### Yen-Ting Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a <a href=\"https://www.kaggle.com/c/telstra-recruiting-network\" target=\"_blank\">Kaggle Challenge</a> aimed to predict network fault severities based on past service logs, for Australia's telcommunications company Telstra Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data from the past service logs is contained within five separate files:\n",
    "1. **`train.csv`**: The unique id of past logged events, its location, and the outcome fault severity (levels 0, 1 or 2). Location consists of 929 categories.\n",
    "2. **`event_type.csv`**: Mapping of event id to \"event types\". Each id may have more than one type. Event type consists of 53 categories.\n",
    "3. **`log_feature.csv`**: Mapping of event id to \"log features\" and their \"volumes\". Each id may have more than one feature. Log features consists of 386 categories, while their volumes range from 1 to 1310.\n",
    "4. **`resource_type.csv`**: Mapping of event id to \"resource type\". Each id may have more than one resource type. Resource type consists of 10 categories.\n",
    "5. **`severity_type.csv`**: Mapping of event id to \"severity type\". Each id maps to one severity type. Severity type consists of 5 categories.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(caret); library(tidyr); library(Hmisc); library(dplyr)\n",
    "\n",
    "REvent_type <- read.csv(\"event_type.csv\")\n",
    "RLog_feature <- read.csv(\"log_feature.csv\")\n",
    "RResource_type <- read.csv(\"resource_type.csv\")\n",
    "RSeverity_type <- read.csv(\"severity_type.csv\")\n",
    "RTrain <- read.csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, all categories from all variables total to over 1300 categories. It is not feasible to simply cast all categories as dummy variables for prediction modeling.  \n",
    "  \n",
    "Instead, the following approach was taken to reduce these 1300+ categories to extract only 90 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the variables **`event_type`**, **`log_feature`**, and **`location`**, its categories were grouped according to that event's outcome fault severity level (0, 1 or 2). This is done by looking at the range of frequencies of a given category towards a severity level, dividing the range up into a number of buckets, and placing each category into the bucket according to its frequency of that outcome. Therefore, the top bucket for severity level 0 will contain the categories that most often occur in an event that had severity level of 0, while the bottom bucket contains the categories that least often give severity level 0. The same goes for all three severity levels. Each event id will have at least number 1 within one of the buckets for each severity level. If the event id maps to more than one category, it may have 1's in more than one bucket, or have a number greater than 1 in some buckets if some categories belong in the same frequency range.  \n",
    "\n",
    "These buckets group categories together based on their frequencies of resulting in a certain fault severity level. These frequency buckets essentially represent the categories to severity level relationship, but on a less-detailed scale, thereby reducing the number of \"categories\". These are used as the predictors for modeling.\n",
    "\n",
    "Here are the steps to generate the frequency buckets for **`event_type`**:  \n",
    "First, we must join the tables to match event id, severity level, and event types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp <- inner_join(RTrain, REvent_type, by=\"id\")\n",
    "temp <- select(temp, event_type, fault_severity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count up frequencies of each event type by their fault severity levels for all events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eventFreq <- temp %>% group_by(event_type, fault_severity) %>% summarize(count=n())\n",
    "rm(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have the severity levels as variables with frequencies as values, we must spread the table to wide format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eventFreq <- spread(eventFreq, fault_severity, count)\n",
    "colnames(eventFreq) <- c(\"event_type\", \"fault0\", \"fault1\", \"fault2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some event type and severity level combinations are not going to occur and will have NA. Replace these NA values with 0 frequency count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eventFreq[is.na(eventFreq)] <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 53 categories in the **`event_type`** variable. We will divide the range of frequencies for these categories into 5 buckets for each severity level. For **`log_feature`** and **`location`**, there are more categories in those variables, and more buckets will be used to differentiate categories better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eventFreq <- eventFreq %>% mutate(buckets0 = cut2(eventFreq$fault0, g=5), buckets1 = cut2(eventFreq$fault1, g=5),\n",
    "                          buckets2 = cut2(eventFreq$fault2, g=5)) \n",
    "## a1 = event_fault0_5_1; b2 = event_fault1_5_2\n",
    "levels(eventFreq$buckets0) <- c(\"a1\", \"a2\", \"a3\", \"a4\", \"a5\")\n",
    "levels(eventFreq$buckets1) <- c(\"b1\", \"b2\", \"b3\", \"b4\", \"b5\")\n",
    "levels(eventFreq$buckets2) <- c(\"c1\", \"c2\", \"c3\", \"c4\", \"c5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bucket name `a1` refers to the bucket containing event type categories that least often are related to severity level of 0, while `a5` contains the most frequent occuring categories for level 0. Bucket names starting with b are for level 1, and c is for level 2.  \n",
    "\n",
    "The `eventFreq` table now maps each event type to which bucket it belongs to for each severity level. We need this information in a wide format with the buckets as individual variables, and values of 1 or 0 (belongs to or not) as values. Again, there are combinations that do not occur (most do not, as each category can only belong in one bucket for each level). These will have NA values that must be replaced with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eventFreq$fault0 <- NULL; eventFreq$fault1 <- NULL; eventFreq$fault2 <- NULL\n",
    "eventFreq$freq <- 1\n",
    "eventFreq <- spread(eventFreq, buckets0, freq)\n",
    "eventFreq$freq <- 1\n",
    "eventFreq <- spread(eventFreq, buckets1, freq)\n",
    "eventFreq$freq <- 1\n",
    "eventFreq <- spread(eventFreq, buckets2, freq)\n",
    "eventFreq[is.na(eventFreq)] <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief glimpse into the `eventFreq` table in wide format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>event_type</th><th scope=col>a1</th><th scope=col>a2</th><th scope=col>a3</th><th scope=col>a4</th><th scope=col>a5</th><th scope=col>b1</th><th scope=col>b2</th><th scope=col>b3</th><th scope=col>b4</th><th scope=col>b5</th><th scope=col>c1</th><th scope=col>c2</th><th scope=col>c3</th><th scope=col>c4</th><th scope=col>c5</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>event_type 1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>event_type 10</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>event_type 11</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllll}\n",
       "  & event_type & a1 & a2 & a3 & a4 & a5 & b1 & b2 & b3 & b4 & b5 & c1 & c2 & c3 & c4 & c5\\\\\n",
       "\\hline\n",
       "\t1 & event_type 1 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0\\\\\n",
       "\t2 & event_type 10 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0\\\\\n",
       "\t3 & event_type 11 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Source: local data frame [3 x 16]\n",
       "\n",
       "     event_type    a1    a2    a3    a4    a5    b1    b2    b3    b4    b5\n",
       "         (fctr) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl)\n",
       "1  event_type 1     1     0     0     0     0     1     0     0     0     0\n",
       "2 event_type 10     0     0     0     1     0     0     0     0     1     0\n",
       "3 event_type 11     0     0     0     0     1     0     0     0     0     1\n",
       "Variables not shown: c1 (dbl), c2 (dbl), c3 (dbl), c4 (dbl), c5 (dbl)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(eventFreq, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `eventFreq` table must then be joined with the original data table of event types, to combine the bucketing results to the event id's and event types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event <- left_join(REvent_type, eventFreq, by=\"event_type\")\n",
    "event[is.na(event)] <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is then grouped by event id's so that each event id has only one entry, and id's with multiple event types have the counts of which event type in which bucket combined (summed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>id</th><th scope=col>a1</th><th scope=col>a2</th><th scope=col>a3</th><th scope=col>a4</th><th scope=col>a5</th><th scope=col>b1</th><th scope=col>b2</th><th scope=col>b3</th><th scope=col>b4</th><th scope=col>b5</th><th scope=col>c1</th><th scope=col>c2</th><th scope=col>c3</th><th scope=col>c4</th><th scope=col>c5</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>6</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllll}\n",
       "  & id & a1 & a2 & a3 & a4 & a5 & b1 & b2 & b3 & b4 & b5 & c1 & c2 & c3 & c4 & c5\\\\\n",
       "\\hline\n",
       "\t1 & 1 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 2 & 0 & 0 & 0 & 0 & 2\\\\\n",
       "\t2 & 2 & 0 & 0 & 0 & 0 & 2 & 0 & 0 & 0 & 0 & 2 & 0 & 2 & 0 & 0 & 0\\\\\n",
       "\t3 & 3 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1\\\\\n",
       "\t4 & 4 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\\\\n",
       "\t5 & 5 & 0 & 0 & 0 & 0 & 2 & 0 & 0 & 0 & 0 & 2 & 0 & 2 & 0 & 0 & 0\\\\\n",
       "\t6 & 6 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Source: local data frame [6 x 16]\n",
       "\n",
       "     id    a1    a2    a3    a4    a5    b1    b2    b3    b4    b5    c1    c2\n",
       "  (int) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl)\n",
       "1     1     0     0     0     1     1     0     0     0     0     2     0     0\n",
       "2     2     0     0     0     0     2     0     0     0     0     2     0     2\n",
       "3     3     0     0     0     0     1     0     0     0     0     1     0     0\n",
       "4     4     0     0     0     1     0     0     0     1     0     0     0     0\n",
       "5     5     0     0     0     0     2     0     0     0     0     2     0     2\n",
       "6     6     0     0     0     0     1     0     0     0     0     1     0     1\n",
       "Variables not shown: c3 (dbl), c4 (dbl), c5 (dbl)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventFinal <- event %>% group_by(id) %>% summarize(\"a1\"=sum(a1), \"a2\"=sum(a2), \"a3\"=sum(a3),\n",
    "                                                   \"a4\"=sum(a4), \"a5\"=sum(a5),\n",
    "                                                   \"b1\"=sum(b1), \"b2\"=sum(b2), \"b3\"=sum(b3),\n",
    "                                                   \"b4\"=sum(b4), \"b5\"=sum(b5),\n",
    "                                                   \"c1\"=sum(c1), \"c2\"=sum(c2), \"c3\"=sum(c3),\n",
    "                                                   \"c4\"=sum(c4), \"c5\"=sum(c5))\n",
    "rm(eventFreq, event)\n",
    "head(eventFinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 53 categories in **`event_type`** are now reduced to 15 variables.  \n",
    "\n",
    "Similar processes are applied to **`log_feature`** and **`location`**, with more buckets since they have more categories. Full analysis code can be viewed in my <a href=\"https://github.com/janie128/Random_Projects/tree/master/KaggleTelstra\" target=\"_blank\">Github</a>.  \n",
    "\n",
    "For the variables **`resource_type`** and **`severity_type`**, there are only a few categories and will therefore be directly cast as dummy variables. The process is shown here for **`resource_type`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resourceFinal <- RResource_type\n",
    "resourceFinal$freq <- 1\n",
    "resourceFinal <- spread(resourceFinal, resource_type, freq)\n",
    "resourceFinal[is.na(resourceFinal)] <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the variables extracted from the 1300+ categories, we can now fully expand (join) the main **`train`** data table with outcome fault severities to match with the extracted variables by the event id (or location).  \n",
    "\n",
    "For prediction modeling, the outcome fault severities are converted to factors (3 levels). In addition, to match the final submission file format for the challenge, the fault severity levels with values of 0, 1 or 2 are relabeled as \"predict_0\", \"predict_1\", or \"predict_2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total <- left_join(RTrain, eventFinal, by=\"id\")\n",
    "total <- left_join(total, featureFinal, by=\"id\")\n",
    "total <- left_join(total, locationFinal, by=\"location\")\n",
    "total$location <- NULL\n",
    "total <- left_join(total, resourceFinal, by=\"id\")\n",
    "total <- left_join(total, severityFinal, by=\"id\")\n",
    "\n",
    "total$id <- NULL\n",
    "total$fault_severity <- as.factor(total$fault_severity)\n",
    "for (n in 2:dim(total)[2]){\n",
    "  total[,n] <- as.integer(total[,n])\n",
    "}\n",
    "\n",
    "levels(total$fault_severity) <- c(\"predict_0\", \"predict_1\", \"predict_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a manageable training data set with 90 predictors, we can begin our prediction modeling. The Extreme Gradient Boosting model (xgboost) and the Random Forest model (rf) were trained, with the latter giving better performance. The `mtry` parameter in the Random Forest model was optimized. Below is shown the final optimized procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "inTrain <- createDataPartition(total$fault_severity, p=0.7, list=FALSE)\n",
    "training <- total[inTrain,]\n",
    "testing <- total[-inTrain,]\n",
    "\n",
    "set.seed(123)\n",
    "fitCtrl <- trainControl(verboseIter = TRUE)\n",
    "modelRF <- train(fault_severity ~ ., data=training, method=\"rf\", prox=TRUE, trControl=fitCtrl,\n",
    "                 tuneGrid = expand.grid(mtry = c(9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the final submission predictions, the `test` file must also be joined with the extracted features by the event id or location. The above prediction model is used to predict the probabilities of the three possible fault severity outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test <- read.csv(\"test.csv\")\n",
    "totalTest <- left_join(test, eventFinal, by=\"id\")\n",
    "totalTest <- left_join(totalTest, featureFinal, by=\"id\")\n",
    "totalTest <- left_join(totalTest, locationFinal, by=\"location\")\n",
    "totalTest$location <- NULL\n",
    "totalTest <- left_join(totalTest, resourceFinal, by=\"id\")\n",
    "totalTest <- left_join(totalTest, severityFinal, by=\"id\")\n",
    "totalTest[is.na(totalTest)] <- 0\n",
    "predictions <- predict(modelRF, totalTest, type=\"prob\")\n",
    "\n",
    "submission <- cbind(id=totalTest$id,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metric used to evaluate prediction results in this challenge is the <a href=\"https://www.kaggle.com/c/telstra-recruiting-network/details/evaluation\" target=\"_blank\">multi-class log loss</a>. With this analysis, we achieved a score of 0.64, where the top score was 0.40, and the benchmark score for guessing equal probability for all three outcomes is around 26. Feature engineering was successfully performed to extract 90 features from 1300+ categories to enable efficient prediction modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Links\n",
    "Kaggle challenge description: <a href=\"https://www.kaggle.com/c/telstra-recruiting-network\" target=\"_blank\">https://www.kaggle.com/c/telstra-recruiting-network</a>  \n",
    "Kaggle challenge dataset: <a href=\"https://www.kaggle.com/c/telstra-recruiting-network/data\" target=\"_blank\">https://www.kaggle.com/c/telstra-recruiting-network/data</a>  \n",
    "Full code files on my <a href=\"https://github.com/janie128/Random_Projects/tree/master/KaggleTelstra\" target=\"_blank\">Github</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
